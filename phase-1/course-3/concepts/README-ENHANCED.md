# Course 3: Neural Networks Fundamentals â€” What / Why / How (with dramatic analogies)

What
- Activation functions, forward/backward propagation, weight initialization, and architecture design basics. We'll demystify how networks learn and why they sometimes pretend to know everything.

Why
- Neural nets are powerful but brittle; understanding internals helps you debug and design resilient systems.

How
- Short, illustrative Colab notebooks with a tiny numpy-based neural net plus visualization of activations.

Colab examples
- See `../labs/course3_colab_examples.ipynb` for a simple 2-layer network trained on a synthetic binary problem.

Humour note
- Neurons are like interns: give them clear directions, and they'll overfit to the first shiny thing they see.
